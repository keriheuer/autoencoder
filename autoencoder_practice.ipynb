{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras, os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "#keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a cnn on the fashion mnist dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# convert from integers to floats\n",
    "trainX, testX = trainX.astype('float32'), testX.astype('float32')\n",
    "# normalize to range 0-1\n",
    "trainX,testX  = trainX / 255.0, testX / 255.0\n",
    "\n",
    "# one hot encode target values\n",
    "trainY, testY = to_categorical(trainY), to_categorical(testY)      #only need this if using labels\n",
    "\n",
    "# model I found on the internet\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# # fit model\n",
    "# model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=2)\n",
    "# # evaluate model\n",
    "# loss, acc = model.evaluate(testX, testY, verbose=0)\n",
    "# print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dense, Flatten, Reshape, Dropout, InputLayer\n",
    "\n",
    "#this is the only one that works but terrible accuracy (only 50%)\n",
    "\n",
    "def autoencoder_two(img_size):\n",
    "    stacked_encoder = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[img_size[0], img_size[1],1]),\n",
    "        keras.layers.Dense(200, activation=\"selu\"),\n",
    "        keras.layers.Dense(100, activation=\"selu\"),\n",
    "        keras.layers.Dense(30, activation=\"selu\"),])\n",
    "\n",
    "    stacked_decoder = keras.models.Sequential([\n",
    "        keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "        keras.layers.Dense(200, activation=\"selu\", input_shape=[100]),\n",
    "        keras.layers.Dense(img_size[0] * img_size[1], activation=\"sigmoid\"),\n",
    "        keras.layers.Reshape([img_size[0], img_size[1],1])])\n",
    "    \n",
    "    return stacked_encoder, stacked_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't work because of different dimensions\n",
    "\n",
    "def autoencoder_three(img_size):\n",
    "    encoder = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', \n",
    "                     input_shape=(img_size[0], img_size[1], 1)),\n",
    "        MaxPooling2D(2)\n",
    "    ])\n",
    "    \n",
    "    decoder = Sequential([\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the one I made and want to use but doesn't work\n",
    "\n",
    "# got it working now that I fixed dimension size and reduced parameters of the model \n",
    "#(initially had 10 million from the dimension size and number of layers)\n",
    "\n",
    "#but training/validation loss curves are \"too good\" - when I check test images they are \n",
    "#weird after resizing and reconstructed images are blank... \n",
    "\n",
    "# try starting over with plotting smaller figure and checking test images before training\n",
    "    #yep, issue was with using np.resize() on the images - rewrote create_dataset() to fix\n",
    "    \n",
    "def build_autoencoder(img_size):\n",
    "    #img size should be tuple of (height, width) of images in data set\n",
    "    print(img_size)\n",
    "    encoder = Sequential([\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=7, activation='relu', padding='same', input_shape=[img_size[0], img_size[1],4]),\n",
    "        keras.layers.MaxPooling2D(pool_size=2), \n",
    "        Dropout(0.25), \n",
    "        keras.layers.Conv2D(128, 3, activation='relu', padding='same'),  \n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "#         keras.layers.Conv2D(512, 3, activation='relu', padding='same'),\n",
    "#         keras.layers.MaxPooling2D(pool_size=2),\n",
    "#         Dropout(0.25)\n",
    "#         keras.layers.Conv2D(512, 3, activation='relu', padding='same'),\n",
    "#         keras.layers.MaxPooling2D(pool_size=2),\n",
    "#         Dropout(0.4)\n",
    "    ])\n",
    "    print(encoder.summary())\n",
    "    \n",
    "    decoder = Sequential([\n",
    "#         Conv2D(512, 3, activation='relu', padding='same'),\n",
    "#         UpSampling2D(2),\n",
    "#         Dropout(0.3),\n",
    "#         Conv2D(512, 3, activation='relu', padding='same', input_shape=(19, 19, 512)),\n",
    "#         UpSampling2D(2),\n",
    "#         Dropout(0.3),\n",
    "        Conv2D(256, 3, activation='relu', padding='same', input_shape=(19,19,256)),\n",
    "        UpSampling2D(2),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(128, 3, activation='relu', padding='same'),\n",
    "        UpSampling2D(2),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(64, 3, activation='relu', padding='same'),\n",
    "        UpSampling2D(2),\n",
    "        UpSampling2D(2),\n",
    "        Dropout(0.3), \n",
    "        Conv2D(1, 3, activation='sigmoid', padding='same'),\n",
    "        Reshape([img_size[0],img_size[1],1])\n",
    "    ])\n",
    "    print(decoder.summary())\n",
    "    return encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying with a bit smaller version of build_autoencoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dense, Flatten, Reshape, Dropout, InputLayer\n",
    "import keras\n",
    "\n",
    "def build_autoencoder(img_size):\n",
    "    #img size should be tuple of (height, width) of images in data set\n",
    "    print(img_size)\n",
    "    encoder = Sequential([\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=7, activation='relu', padding='same', input_shape=[img_size[0], img_size[1],4]),\n",
    "        keras.layers.MaxPooling2D(pool_size=2), \n",
    "        Dropout(0.25), \n",
    "        keras.layers.Conv2D(128, 3, activation='relu', padding='same'),  \n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        keras.layers.Conv2D(256, 3, activation='relu', padding='same'),  \n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        Dropout(0.25)\n",
    "    ])\n",
    "    print(encoder.summary())\n",
    "    \n",
    "    decoder = Sequential([\n",
    "        #Conv2D(256, 3, activation='relu', padding='same', input_shape=(29,29,256)),\n",
    "        UpSampling2D(2), #, input_shape=(29,29,256)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(128, 3, activation='relu', padding='same'),\n",
    "        UpSampling2D(2),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(64, 3, activation='relu', padding='same'),\n",
    "        UpSampling2D(2),\n",
    "        Dropout(0.3), \n",
    "        Conv2D(1, 3, activation='sigmoid', padding='same'),\n",
    "        Reshape([img_size[0],img_size[1],1])\n",
    "    ])\n",
    "    #print(decoder.summary())\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232, 232]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 232, 232, 64)      12608     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 116, 116, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 116, 116, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 116, 116, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 58, 58, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 29, 29, 256)       0         \n",
      "=================================================================\n",
      "Total params: 381,632\n",
      "Trainable params: 381,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#compile model of choice\n",
    "\n",
    "encoder, decoder = build_autoencoder([232,232])  #304x304 from matplotlib figsize=20.3x20.3\n",
    "autoencoder = Sequential([encoder, decoder])\n",
    "autoencoder.compile(loss=\"mean_squared_error\", optimizer=\"RMSprop\", metrics=['accuracy'])\n",
    "\n",
    "#autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make data set from all the spectral images\n",
    "\n",
    "def create_dataset(img_folder):\n",
    "    from PIL import Image\n",
    "    img_data_array=[]\n",
    "    for file in os.listdir(img_folder):\n",
    "        if '.png' in file:\n",
    "            image = np.array(Image.open(img_folder+'/'+file))\n",
    "            image = image.astype('float32')\n",
    "            image /= 255  #normalize pixel range from 0-1\n",
    "            img_data_array.append(image)\n",
    "    return img_data_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = create_dataset(\"spectra\")\n",
    "training_data = np.array(img_data)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = create_dataset(\"z_1p1_1p2\")\n",
    "training_data = np.array(img_data)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 90, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEIAAAD8CAYAAADDlHLtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy9ElEQVR4nO29eXBc133n+zl36X0FGhsBkCBIioskaiElU94tS47skWO/spM4ybOTN3F5XC/Jm1RmJlYyNXGSN5myMzP2OJOpTFyO/ZzEW7woYzm2ZUtetFoiKVHivhPEvqP3vut5f5zbTQACQIAAreaUvlVduH3Xxu/ee37nt31/QkrJawDt1f4BzYLXBBHgNUEEeE0QAV4TRIDXBBHgughCCPGAEOK0EOKcEOKh63GNjYbY6HmEEEIHzgD3A0PAQeBXpZQnNvRCG4zr8UTcDZyTUl6QUtrAV4H3XIfrbCiM63DObmBw3vch4HUrHZDL5WRfX991+CkLceTIkTnXdbNLbbseglgVhBAfAT4CsHnzZj71pe8xXqzxrlu7iIevz8/q7OzML7ftelxxGOid970nWLcAUsrPAp8F2L9/v/z0Y6eZKtlsbo1x15YWfCnRNYEQYlUXlVLieD6mrq36mPm4HoI4COwQQmxFCeADwK+tdIAEBueqzJRs/uN3TvL23e1UbY/bejPsaE+QCBt0pCP4vkQChiaQwOJ/99DALPf0t6pzSonnK2H6ErSryGbDBSGldIUQvwM8CujA56WUx692XFsizL7NWZ46O8Wx4TxCgKlrtCXDpCIm79vXzUzZJh4y6MvFKVsumViIqKnRmgizNRdncKbC1lyclniI06NFDg7Mcmt3mn8+OsL2tgSuv7yGvC4vo5Tyu8B313LMv3vHLjrSYVriIX52YYaWeAjL8RjN15irOHzqh2eo2B6mrpGJmliuj+P5CAE7O5JkYyGODuf5zGNn+ZW7enni7BTHh/MkIgalmhKa5/vLXv9VGyznQwB3bsmQjpr88YM3M1GsEQsZVGyX2YqN78Mz56ewXDUG3Le7Hdv1GZ6rMl6weOOOHCdHC+zZlKLmeLxhe46zEyXG8jUyMZMP3dPJ9rYEH/z08u9HUwgCIB01kUDE1NjcEgvWhhrLt/Vm0ASN976+ro7t7QngyrixszPJ+ckS/bkEIUPD1NVnOTSNIFxfcn6ixM7O5JKjvh6sMvSl7+ritYmwwW09mVVrkKYxuizX54mzkxt2PiGU6vV8pVZtd/nxAZroifjvj59lYKaCJyX6vPVLqcm14PDADHMVh6LlrrhfUwhCAv/04jDxiMHvf+0lurNR0lETAbQlwxRrLomwwc7OJMdHCpi6YLbiIKUkGtLRhSAdNXF9SWcqQjpqMlOxKVQdHj0+zrmJIkIIXK/JtQbAm25qY1MmwiMvjfL0+Sl8XxILGURMjWwsRM3xgsddDawdqQi+lHQkI3SmI0wULUbzVb5xeIh7+lt5+vwUM2WbWEjn/37rdjQNnvyT5a/fFIIQwO+8bRu9LXE+dE8fFdvFcnwysRBSSlLB3fZ9ScjQ0IRozBQ1TSx4dU6NFYmGdH79wGYAXE+Sjqmn64bQGlta4wDkEmEgjJTymmyGbCxE2NBIRsw1Hdc0WuPUWJFHXhpR9kTgLJLyyvJq0ZEKk4ktFMJqztMUT4QEPvJ3h3B8ybmJEi3xEJsyasCsOh5tyTBI0DVBxfbwpSQTC2HqAtv1aU2EG6+K60sipk7FdvF98KRkumgxW3VWFEZTCALg/ft62NqW4PGT45wYLeD5Ek0IYmEdKaFqe4RNjZrjEwvpxEMGju+TjZmN1+rkaIGQrrFvS5aDl2aZrdhoQnDzphSW669odDUem1fzs2/fPun5vvR9X9ZsV9quJx3Xk67nBx/13XE9abue9DxffXy/cZzv+/LUaF7WHFf6vjrOcoL9g+0dHR2XlvsNTfNEaMHAGDb1JbZefdCUUj1BAjWj1AUNm2RV11/1njcIlOtm7fjfRhBCCAxdQ1zjhLxpBCGlZKZsr1ldzkdvNoq5hHXqB5OxldA0gjg1VuCrz19u2BBSSvw1CkUPfJmLB8Inzk7y9PmpFY9tisFSAv/l0TOMF2sMz1U50N9KLKRzeabC7q4UXekIEVPHdn1a4iGGZqvomqBqu0RCOomwQdVWtki+arOzM8X5iRInRwskIwbfPTrGy0NzeD9vn+W14Ohwnqip89WDg3zt4CCmrmG5HqmISTSkowmB7fn0ZKNcmCxjaMrXIATs6EiSiZocHpglbGi8945uHj0+xmi+hutLWuMhsrEQznqsTyHE54EHgQkp5S3Buhbga0AfcAn4ZSnlrFDGwWeAdwEV4DellC+sRhB7ulK8b18P/98zl+jORLk0VWZfX5ZDl2bJxkyKNZdsPMS2tjgP3NyJ60sMTbCjPYHjS7a3JRiarZCvOuzelCKXCDNZtNjenuC23gyTRYtf/PMVRoKrTXaANwN3AsfmrfsL4KFg+SHgk8Hyu4DvoRT/AeC51U6onj0/KcuWI2fLlqzZrhyercia48rpUk1WbVfOlS2Zr9jS9dTkyPP8xuTJ930ppWwsW44nT48VpOddmWw5rrfihGpVM7/gzs8XxGmgK1juAk4Hy3+Diny/Yr+rCcL11D+zEbBdT54ZK7xi/UqCuFat0SGlHA2Wx4COYHmpAHD3UicQQnxECHFICHFocnJyTbPAlVC1PXRN0JONXX3neVi3+pTq1q9Z+UspPyul3C+l3N/W1obleJwdL65rHgFweaaClBANXZmq+1Ku6KaDa9ca40KILinlqBCiC5gI1q8qALwU/vjbxzkxUuBjD+yiOxshGwsF7v0UnpSEA8+U6/uN2WPI0ChbLhFTZ65iY+oaM2Ubz5dYrofl+Lw4OEvV9hicrV4XM/zbwG8Anwj+/q95639HCPFVVE5Eft4rtCwk8NPTkySjBh/5+0PkEmFSEYPB2So7O5IIoTxX6ajJeKFGvuqgaYLWeIjxQo3elhgCODtRImLqvHlHjqfOTVGsuYwVaqQiBmFDx/bWIQghxFeAtwI5IcQQ8PFAAP8ohPgtYAD45WD376I0xzmU+vy/rnb+On7h5k7u39POydEiZ8aLGLrg9dtzhHSNwZkK8bBBayJEOmbSn4tTqLnEQzrZeIi2ZBjXk4zmq5wYKbC7S/kf5ioOZdtlT1eKm7vTvPcTK4xDq9Ea1/uzb98+6bieUou+3/Ah1NVf3S9RX/b9pT+e78sTI/mGLyJfseUTZyYa574h/BFG4GEWgFY3nII/8+2oZSJ+83cH1PjhS0k6ajbOveL11/Zzry/qg9m1eK/r6ExF0ITSFKausacrtSpN1DTWp+P5nBwtYns+vi+pOd5VTeelkI2HAuPLYapkYegahZrLkcG566I1NhQS+NunLvDwiyP8ybv3UKwplZhLhNjWnsDQBK4vMTUNhHoFPCnR5z05jqdShYo1h0wsRLHmcnQoz/6+LIMzFf7u2QFWkmtTCALgc09dZKpo87FvHqViu3SkIvTn4tzak2Zwpkp/WxxfSra1JZgsWpRtl3jIIGzqvOWmNr7z0ghPnZsiZGj87r3b+f6xMZ44M8VfPn4Wy/WYKFo3hhkuJfTn4lyYKgMwVbI5OVrgByfGsV2fsKkhg9iGLyUCNbkCuL03Q83xOTqcJxE2COka335pBMv10YUgETGIBIPncmgaQdyztZXXb8/xhacvMpqvkYoa7NvSwkQwgao5Hv1tCU6MFLirL0smFuLloTlaEyF2dqSYLqs7no4a7OlKcXykwMWpMnt70jxwSydzFZs//6sbIPb5S/t6uLu/lY5UmCODc9y5OcuOjgRhQydkaBSqDumo8kuIwFV/abrMrd1pDE2j6nicnyjR3xanbHkUaw6uL/m1120hGTGoOR6fXMmwe7UnU/UJVanmNCZFi/0MS2H+RKr+3XG9xvLQTEWOF6oL9rshJlSW6+P5KgUgbCwV5FmIxXMN5c5X61xfkooaJMIGQghmyjaJq6Q1N808YrZi8/CLwyuO7KuF50uqQWIJwGRRjTMroSmeCAn85++f4shgnnt3tdORiiyIT6x1pqn8D1dSC8byNQZnqise0xSCADg4MMtcxeHj3z7Om2/KkQgZJKMmYUPj1u406ZjZmEAp77VallLFPOvxDD3wbru+csYIIXjy7FQj5rEcmkYQm9IR7t/dwTdfGOLJs5MIBBJJ2NDpa41xU2eSO3ozTBQtBmcqSMByfMq2y9t3tVOxPfJVh2TE4LbeDKP5Ghcmy0ipAjzdmSjOCimGTSOI/+ftN7G3J008bPCT0xPkEmFu6U5TtT3GCjUGZyoMTFeoOR59rXGKNYd81aE7E+XMeInOdITnL82Qiph4vuSpc1MUai4RQ+PBvZu4ozfT8B4tiVdbddbVZ93PYDmecuXbbsMPUVepVduVU8WarNmurNmuLNWcBXkUxaoja44rPc+X+YotD12akaWaIy9Pl6XluLK9/QZQnxOFGoaukUuotKHFqKvUyLz8ifCifRKRK/9OMmJwx+aMyroJHLkrjblNoz6//fII/+2xM5RtD8/3F9yta4EQopF8Uk9HXglN8URI4HNPXmSuYlNzPP7F3i7u6M0yVqgRMXU60xFCutZIGPPlFQ1Rx+J/VAlRTdQMXXA1eTaFIOCK7v+nIyM8fmqC7W0JBqYr7NmUoicb5UB/K+mgYGVotkIibLCrM8lMxaEnG6U3G6VkuViuTzYW4sx4kcszFcbzNTa3xpkuWytefzVe7F7g71DRLAl8Vkr5mY0OBPfn4tzem+FHJyco1lwODcwigJ+emUQI+NYLw+iaIGRolGquysEO5gy7u5JEDJ2L02UE8O7bNvH1Q0NUbBchBNmYSSpqri8aDrjAv5FSviCESAKHhRA/BH4TeFxK+Ymg7Pkh4GPAO4Edwed1wF9zlbpPAfza6zazoz2JqWn0t8U5N1Fiz6YU5yZKCAFPn5vG8yXxsM7dfS0IodKPuzNRWhMhilWX6bJNyXKZKFqEDY18VbK9Pc7+LVl0TfDkSq/HWlUdKphzPxsYCN63b5+s2a70fKX2KpYjSzVHer4vy5Yji1VH/uT0hDw2PCeHZyuyULUb7nrL8Rrph8eH8/LY8JysOa585tyU/MpzA3J0rirLliOnijXZ3t6+rPpcqxD6gMtACpibt17UvwPfAd44b9vjwP4lzvUR4BBwaPPmzdL1fDlbtpY1va9mlkspF+RU1k36+cdsSDRcCJEAvgn8npSysOipWnMgWC4KAp8eK/DZJy6sdP2rqkBTV/HR+r7aKo6pY1VaQwhhooTwJSnlt4LVGxYIVjlUpxFCYLmqhDFUD/iswfKUUjYqftZqsV71iQi0wN8CJ6WUn5q3qR4IhlcGgj8kFA6wykDwy8N5Lk2X+eg/HOa//+gcRwbnODFSYDRfpWS5uJ6aZPlS1Wh5/pKvrkoLCM5ZX1+2XGbK9orXX80T8Qbgg8BRIcSRYN0fscGB4O5MlH1bsnzx2QGePjfFF56+iKlpZGImbckwfa1xdnQkiJo6Z8ZL6JpKNpdAMmwQNjVmyg6+lMRMnXOTJTQhGJypMFm0GMlX1+fOl1I+xfLJ0G9fYn8J/PZq/vn5eNOOHPft6cRyfTpSEcYLNQo1h1TEZKJocWm6zAuXZ0mEDQo1lwP9LXzl+cskIwY3b0rj+ZLnLs5QtlxOjxX56ZlJypZLyXLpa42zKRNZMTt/wxlFrgX79++X3/vx06SjJnMVm1TUpOZ4DT+jEIKJQg1NE0RNnWLNoSMVoWx7hAyNkK4hBBSqDoWaS2cqQrHmcGGqzHi+xt1bW0hGDPp6ewbGx8f6lvoNTTPFziVCVGxVpCKEWGBlAnSmI4ASSiqqKnTS0YVDXCYWIhMLAdCaCJONhag6XoOP4oawPr9xeIj/9N2TVB0PeGX50WrU52IIAdElyx5eiaZ4IiTwqR+cIRk1+LtnB3jHng4mSxa92Rg1x2NTJoqhCzQEVccjYupIKfECQy1sKPIMEZyrbpTans/gTBXL9Rom+XJoCkEAbM3FuHd3B3/x6Gk+9+QFqrZHMmJi6oKudJR4WCcZMRmerdCeiqAJgeUqP+X+vhY8XzJbtgmbytk7VbIp1hyOXJ7Dk5JE2Fi30XXdIYBPvG8vEkhFTIbmKvRkY1iOR082xlzVIWrqlCyHRNjACDgkMjGTiu0RDxmULJdizeHSdIWbOpJ4fpGoqbO/r4UP3bOFkuXynY/dALQJm1vjSCnZ3BLD8WQjriGEWNZLNX/MqO/TmiiyszPJ7b0ZXF8yWbRoS4ZpT0VWTGptGkHAlX8sZLwynLeaYxsCkyA0gaFBVzqyquObRhAq52F9+VOguGrqp1jLuZpGfU4VLYaukh27GrQmQtd0XNMI4vvHxvhfR4ZXLlK9CsQ8E3ytaIpXQwJ/88QFypaL7fp86PV9ZGMhPH/hoNnYX64+DXG1+zaFIEBV4rUmQnzhmUs8emKcW7vT1ByPN27P8ZadbeQSilAjEzUp1BwcT5UoOZ5PyFAP9nwiHl+C6/lMlix+cnqSu7e2rHj9phHEltYYe3szfOm5Ac6MFTk7XkTXBN87OkZvS5TXbW3l2EienR1JCjWHiu3Rk41SqLnc099KxXYZL1hkYibb2hK8eHmWmbLNuckSl6cr9LclbowJ1Ufe3M/uTSlu6U4xNFtlqmixqzPFmfEiF6bK/ODEGJsyUbLxEKmoSb7qcGGyTCZmEjI0ao6gYru8eHkWx/Mp1FzKlsfrt+X4pX2KeeDJFX5DUwgC4M03taFrgnfv3QRAzVGPvBBQtlzOT5ZpT4bJJcKqwk9Kpks2LfFQYxzxfMloXpnribBBIqw3bBCAj94IjCJCCEbztcYEaH4FTjJicltPurEfgIZomOZ1GLqgJxtdsN9q0TTq0/V9BqbLy25frVq8VvXZNIKoOT4z5ZUTvq4nmubV+NbhIV64PMvrt7USDemYuqYCL9ra6v/n51bVUXM8rPUykwkhIsATqLwMA/iGlPLjAXHnV4FW4DDwQSmlLYQIo4LG+4Bp4FeklJdWuoYE/vqn5/Gl5EOff45kxKS3JRYMeAa5RKjhm+jLxRnN1/A8JaSao9Ro3WINGRqt8TBly+XkWIFE2GBotkrU1Nedi20B90opS0Gg5ykhxPeA3wc+LaX8qhDifwK/hQr4/hYwK6XcLoT4APBJ4FeudpE3bG9lay7B3z51kZb4FY9SImxwGijbLlIqMq5s3CQbCzFTtulrjVOyXHwpOT1WpFRzuX9PB0+fm2JwtsrNm1J0Z6PMBXSQy9+NtcU+Y8ALqOj2FGAE6+8BHg2WHwXuCZaNYD+x0nnrKci268lTowU5nq82cqNs15OO58mq7QYB3ysxzflxTt/35fMXpmXZchq1X/VYan3fdacgB6Tfh4HtwP8AzqOCvnUmvPkVv41qYKloX/Oo12dq0TkXsCBHTJ1CzWFnZ3LBtfVghDCWGNbnjx1SSu7YkkEXVzhm6h7txfsuhVVpDSmlJ6W8HRXHvBvYtZrjrnLOBUFg2/U5PlJYV86UoS3NgLzYI74U1qQ+pZRzwI9Rr0JGCFF/ouYHehtB4GB7GjVorojJYo3HToyv5eesClJKzowXOTVWXHG/1WiNNsCRUs4JIaKoJJFPogTyfpTmWBwE/g3g2WD7j+RVbocEPv7t44wXLJ4+N83WtjgThRptiTBhUyccULXqmsq8nynb2K5POmpiuz5m8N5ICbqmZqK6UJU+M2Wbp89NM1O21601uoAvBuOEBvyjlPI7QogTwFeFEP8ReBEVMSf4+/dCiHPADIoX+6rIxExu6U7z777xEtGQTqnmsq09wWzZJhVRhlUuGQKpCtsipmIZ0TVBezJMMmJweGAWXRO8cXuOM+MlSpZL1fZ44JbOoCZs+es3Tezz8SefJWxoDM1W8XwfTRNkYyGmSlYQ2xSkowYhXSdsKmNMyiu5EELQyMivOh4jc1VyCSWgOvVjZ2fnwNhYk8c+00E8s85mXIeidVwd6t5vX0pyCVUzvlo0ja1RT+jYiCc0ZGhk42tz4jaNIM5OlPjiM5c25FxaoErr2HD1eT3x+acucvDSzFVThVcDLyiprqNiexRrNwgL8sGLM5Qdj+G5Kj3ZaCMp7GrJYYvvtBAqYj5dstgShBGPDeeZKq0zBfnnharj0ZYI84ffOsq9u9oZzVdJRkxSUYO33NROxNSIhVT9pgw4ZEbzVUo1l1wijOWq7Jl0NIQRtJJwPZ9CzeHR42McGZy7MSqBuzIR3n1bN3/y7eM8fX5KPQUIdF3w+acuAaoGQwuYAOJhnemSmlgd6G/BCqboqajJ/3FHN+cm1DxiaKbCzs4kyYi5Ilt6UwhCAL9612a25OLc3ddCPKwzPFfl/t0dDMxUuDRVRgtShnZ1Jhuct4mwwe6uJFtzCUqWy2TR4sJkiVu604QNjbmKw7272nnHng5myjbffWj5IbFpJlRPPfscNcfD8SQRU8PxfDLREL6UFGsumiYI6VrDs13H/PFjpf9F3CgTqsdOjjM0W+Vfvbl/wXpDW/2cYD2R9KYQhAQePznOwUuz7OlKNbjzfSlpjV+hel4qaWS5mKiUktmKKqz3fJVvtRKaQhCg6jFKlsvv/+MRcgkVyKk6Hvu2ZLm9N4PnKxKNsuUyPKeINVTFsNbInLNcj6rjkUuEyVcdnjwzxZZcjDNjxUa23nJoGkHc1pNm/9YW/vLxsw3/gUDxXNZNalPXGhyWqahJe8A/1ZFSvXuG56qMzNX44IEtPHt+moMDMyTCRkNb3BCxzz945y42t8ToSkcZmC5zarTI1lycsKl8EXZQy9WejNDXGmOiaGF7PltzcSq2hy4Ej50cx0tJ8lWHSEijPRnm5k1pcokQvS0x/s1nlv8NTSEIgO1tyup8994uPCmxHJ+oqS/QEL5USaT1VbI+7USND/fubg9YRVS23bmJErcHfXoMXfCHSzk+AzSNIODKdNrQNIzwK3/0YjKuBUpCKO46tahSmLe0xlSi6iq0SdMYXdNlm28eHlrXORbHPduT4VVHyZpGEA+/MMRXnr/MeMFaldm8GqwlINwUr4YE/uFnlxmcrfDvHz7Kb76hj2REaYX2ZBgtqO+c32nlapg/51gNS0lTCAJUoHZXZ4ofn57g4KUZwobGjo4k29sT3Le7gyODc+ia4KaOBKmIiWloOEFvDYDuTITZikPE1AOWIRddE3z36ChSqk4sK2HVggi82IeAYSnlgxsZBAa4uTvFXX2tDM8p07pQc5ksTfPM+Wm+fmgIx/PxpSLW0IS646YuyMRUd7f2ZJjLMxWSEYO33NTGidECUyWbp89N4fmSXCK8YfOIfw2cRNV8goptbEgQWAB/8MAuNCHY0ZHgmXNT/OjUBN2ZKFXHoz0Z4eDADDs7koQNjW1tCY6PFMglQ0gJ9+5qZ6Zsc36yhONJxosWz5yfxtQ0OlIR3nVrF8mwwUPrbTSCimQ9DtyLKnAVbHAQeH4wt1BVJBgzJUsOTJdlvmLLi1MlWbYcOV2ypOV4suaooHCdtLNqu3KmZMlSTZFpXJoqyZmSJZ8+Oykd15MVy5Vt660EBr6BetTfGggih2qAXN/eS8CbDRwDeuZtOw/kljjngkrgqu3KlwZnX1HFu5oK4DrqxOHzv/u+L4dmK/LCZGl90XAhRJ0u/rAQ4q1X23+1kIta4X75ZwM88vIof/DATjKxELGQzoXJMpsyUXyp6OGz8RBly2VgutLovJSvqEK3SEjH8XxG5qrc0ZvF9X2mSzbPX5rhwmSJsuWtm73wDcAvCiHeBURQY8RnCILAUqUGLBUEHlptEFgC33xxiNZ4mIe+dTTgs9RwPEkmamJ7Po7rk4yYREwtmDlquJ4ywNqTEVriJucmypRtl/fe3s2PT09QqDqMF2rcsy1HMmKsaIqvpu7zD4E/BAieiH8rpfx1IcTX2aAgsAB+456tvOPmDi5Nl7Fdn4ipEzV1IqZOzfFwg/TievTKnMcwos6hLNTjIwXu3JzhLTvb8AM+qmzwhH12Je7b1YwR897rtwLfCZb7gedRFb9fB8LB+kjw/Vywvf9q5108WK52TFgM1/PlyZH8NbEFrGlCJaX8CfCTYPkCKmlk8T414JfWcl5Yf8HKUudayxmbxtbYKFxrM4KmEUS+Yq+7iYAmVMWw5a7sllvy2Gu+6gbjqwcv8+ffPUm+qir+F41Nq4IQgrmKs4CyUUoVB63YN0js8xuHh7k8U+HDXzzE/Xs62N2V4vJMhe3tCba1JYiHdUxNYzhfJaRrJMIGrucTDRtoKC1ScTxmyjbZeAjX9/F9Zcw9/OIwvUE8dTk0hSBAlSL05+IcHpjlhcuzpKImpZqLaWh0JMNkYiFa4yFOjhUwNI2OVBjL9dEE9OcS5JJhDl2awXJ9fvP1fRy8NEPF9ihZLhcmS6SjoRuDvfCNO3L8yzds5X/8+Byd6Qg/OT1JbzZG2XK5Z1srp8eL3NSR5M4tWUbzVTShUouyMZPubJSwoWNqglNjRXwJ4wWLXCJEsQb/+u03EQvpPPNnK/yAtcwjrtdn37598plzE1c6KXi+PDdRlCOzFTlVrMmK5S7MovVeaYvUO0NemCzJ0bmqLFRt6fm+PDo0d2OR/+7b0qo8UIGHdlvbwlyq+YUsy005wqZOxFTx0Xor3N6gE/0NU+VX7+Zq6tdWeFJHazy8QFCK385rZNwth6YRRM3xOTGa587NWWDlyDYs9EkujolqwfeS5TJdsvnBiTGcG0UQp8byfPaJC/y/77mFfNVhsmiRS4Y5NVbE8Xxu783geD4nRlS7265MhMvTFVxfckt3mrLlMl6ocfDSLO+9o5ujQ3OcGC1wcrTIZNGiJR5q/kQRRch1hiODc/zS3zxLsepSdVQqkOP5uJ4kGTEQgkZz5IihYwWv0l1bW5ASDg/MKjIvQ+Obh4co2y7ZWIgH93YRDxk8vcJvaApBAIQNjX/1lm18+bnL9LRE6c3GsFy/Uemra4KOVJjuTBQpYVNG8Vfu7UnTETCMnBkvMjJX5Z23dHHn5izxsE5XOkpPNoquCT5xI4T8PvLmfu7a2sqDe7tIBrnXqhWE0hKzFZv2ZKSRerzAFxGMCXf1tXB2vEjE1PiFmzvWNOg2hSAE8Lr+VoQQbM2p1teLE0A6U1fol5ayr0VdQlybSd8UgoAg0o1cMmC72n9MCJW7LaVcszCaxvr80s8G+M5LI+tuIjCftK8OKa/eVrcpnggJfPn5y5Qtl625ODs7U+iaaORCrOXuXp6psLc3jSZUvHSmbHNuosjFqcqKc5OmEATAZNFirurwRw8f46Nv6actGWGiWOPW7jQhQ6MjGcHxfTQhKNXcRk8eQxNomsqBKFsugzMVLMfH11UP8a8dvMzDLw4zVbKxmz11CJQ/YVM6wvGRPH/08DEipkah6tKWDHOgv5VNmQgD0+quHh3Os6U1TsVW9M9v3J6jNR7ikZdHuTBZ4qaOJAcvzdCZjvD1w0OEDZVwttLbsdpyx0tAEfAAV0q5f6PpoO/f3cF9ezp46FsvM5avkQ/aYQzOVBiaVT08JcomMXWt0S+jLRnmZxemVa1XSZF3PvKyalVVtlx2d6X4L++/jaLl8o5PbwwP1duklPNrNx9ig+igAd6/v5u9PRn++ME9fOflUXIJNSXelInSmY7w0lCeYs1hc0uMmzqSDdfb67flmCpZJCMmAhiardDTEuNAfyupiEEmFmJHRwI/eI2WxWr8Bag7nlu0bkPpoC3nSnfHqu1Kx/PkXMVuNCaaLKguChXLXTY2Ov97/djRueqq4hqrVZ8S+IEQ4nBQwQvr7AssFvUEHplT3LZakAhmaBrpeY2JWhMhwqZONKQvYDienx40/3s6ahLSlUtvNVitIN4opbwT9dj/thDizfM3SnXr1zQBkPMqgXNtbXz828d4+tw0E8Vag9i37s2+VnKMDc+hklIOB38nhBAPoyJcG9oX+NhIgd/58gvs6kpyV5+iZo2HDG7tTrOrK0UqYjQkrQVVOqqdJehB9gzQ4JuQKEqnquOpZI7SOlmQhRBxQJNSFoPldwB/xgb3BUaqKt9jwwVOjBQCw0r14XvDtlb0oMOjoal1EwWLaEgFirsyUXKJEBMFi5s6Erx+W47nLs5weqxA0XJJRgxOjRbXnRbQATwcPGIG8GUp5feFEAfZQDroZMQgHjYYmq0Aqm9n1faQUvLj05M0ivaCMibL8UkEx1Rsj5cHXc5PlrBdnzfsyPGzC9NMFW3iYZ37dnewrT1xY7Ag/+XXvs+lqTJj+RoAezapBsdbWuOMzFUxgik3wOaWOIWqQ3sq3CAJVumHcGq0SHsqzEzZ5thwgQPbWulrjREN6Wzu7m5+FuQD/a3c1pMhX3VoTYRwPdnonXNbj+K9NgLemToWD4RSStpTEQRq7DjQ37qgH/BK42bTCKLeNCgaUsXvi1vvGUuQ9y2G6ylNEzb1IG/7BuSzhIUNhK4FludftUBlOTSNIHypWIzXM2b5/tX9DsuhaQQxPFvlE98/tSLHw9XgS7lARdaL7leTXtA0Y8SnfniaFy7P8dMzE+zqVMm9qaiJhmquXndJmrpoqMH6a6QJRQY+v90EwKXpMv25BIOzFSrWDZIfUai6fOCuXn7vq0eUjWHqhHSt0dUxFTUwgjYT44Ua8bARZOsLOlPhRgFsWzLM/r4WypbL8xdncDyfwdlqo5Z0OTSFIATwHx7cg2lotCUjXJoqk0uEKFkuXekoF6fKpKIGA9MVYiGde3d10BJX+ROxkEE6alKyXM6MFzF1DUMTHBvOc3K0wIH+Vt62q509XSl+8Ecb44+4rtjSGqNkubzvzlcYqgsgeWVco4637WpvrL9vdwcl2yVm6o0Es5USzZpmsMxXHX54YhwpF84VxCJzu06ws3i9WLRe0wSpiBmMLzdILz+AP33kOC9cnuP23gxbc3Emi9aClONrRV0th6/SXqIpBCGBJ89OMV2y+dNHTnBPfyuFmoOhC+7qa6EjmDaXLJfWeIhCzSVsaHSmIwzOVEhGTNJRE4kMxgiNyWKNmutzaarMf370NPu3ZG8M/oh01EQg+OmZSZ44O9mIZ0TMiwgUPaOUkmREEf+GDY3NLTEuTpXZsylFKmIyOFshYupszcV5YWCWmuORrzkg4cyNwB8B8G9/YSdhQ+OxE+N4Ab+UJ1V2frHm0hIPkYqYOL7fMMhCuoahC+7b08HwbJUXL8/RkY4wlq/SlY5Qqrns78syMF3hvj0d/Og/NLnWEMADN3cigTfvaMOTEl0InMCI0jXRCOTIRdXAnpQYmkZnKsK+LSrb5sRogd1dqUYcw/X9QGg3QFqAL1VyaCykYwj1g5dsKL/ophrilVbp5pYYAuW2A9C1q/fhaRr1eX6yyN8+dRGJIt5Zj/GVjJivSCu4YWyN//qDM5wZL3FTRwLPh7u3ZomFDKIhfcEEqmSpes753ZZ8ecXe0IRAF6pZev21OjtebKQbLoemEIQEXhpUkazf+9oRsrEQuzqTTJdt3rg9x3TZ5pZNKRxPcnmmTM3x2duTCTgjKjie5I7NGV66PIeuCx64uZMTo0VevDxLLhHm8MAs/lVSA5pCEAC39qR56842/usPzjBRtBqG1Wi+xnTJ4lvBQBkJpszfPz7WsEa7M1H++eVRLs9UcDyfw5dmOTQwy1ygZm/pTrO7M7l+9SmEyACfA25B3cB/iQrlbUgQWAC/fvdm9vZmGo+8LyU9WVXh+8MT45i6xlihxp6uFJ3pCKmI2dAGQqhk1XMTRWqOz87OJO+5w2JkrsrOjiSZeIieTJS/WiGZbLWxzy8CHw6WQ0AG+AvgoWDdQ8Ang+V3Ad8L/r8DwHOrycWu2u4rcqvrH2dRZ9el6r5835fHhucWsCQv3m+l2OdqhJAGLrKompcNDgKvF77vy7F8VXorFMatNwi8FZgEviCEeFEI8bkg4rWhQeB5grtmZGMhhmar13TsagRhAHcCfy2lvAMoo16FBqRcXxC4ra2NsuWuqytTPdfSXqKey/PlVZPUVjNYDgFDUsrngu/fQAliQ4PAn/7hWU6NF/jz994aEPvCRNFSFEu+bDQy1DWBoWv4vqRsqzSCqKnjSclU0WJ4rsrmlhggsD2fyaLFdMli+ioe8tVUAo8JIQaFEDullKdRXV9PBJ8NCQJL4J+PjmLogl/73M9UmpCEmuvRkYxQslTymOdLRaKhKwZTT6r+wHu6UoQMjZeH8kwUavyfB7ZwfrLE6fEiEwWLmzelmKs42Ctk6K92HvG7wJeEECHgAiqwq7GBQeAPHtjMG3bk+N7RMbrSih2kJR4iYur0tcZwfYnr+yTCKvAbM/UgR1sjHtbxpeoA++LlOe7qy3JussRLg3P0BmlEl2cqPPNn60wdut6fffv2SddbWnUulRa0HLxAczToEmYqcrJYaxx/Q5QyzSfmWwqrcddpQtCRutKXRzUsuXrMFJpoin1qrIAmBDd1XOmmcK2+yvqgmI2tbGjNR1OY4RL43tEx/uL7pxucD6BimfMfX+AV35fCbMVp2BV1tequENyBJnoivn1khKmyzSe/f5qS5XJrT5pUxKQrHSGXCNGVVpW8M2WLYs0lHjZorTcvqzhk46EG80ih6lCsOYR0jWhI5+x4iemyte7UoZ8LikGz868dHEQieeSlEUy9XrpokIwYRExd9Q8P4hQhQ6M7EyUbN2mJhbgwVeaWTWlaEyEeO6laVJQtj/HgGHeF3jNNIwhdE+xoVwFbU9cxNEXC15aMYOiK+VhK2JpLcHtvBk2DsXyNdNRk35Yso/kauWSYmu2RiZm0JyPEQjqFqsP79/WQihp8eINSkK8r3nlLJ798Vy9Ds1X6c3E0IRiYqXBXXxYRZOQnwgaO75MJ6FsRSlPUU4XmR/TefdsmDE1rmOpSwkebvSewAD78pn6SEYM9XanGAKdoGNV4nliUS2Qs4nRcTPFYz9itO26FWFkLNYXWAMVqXnOuvMNCiBXd7xuNpngiJPCXPzpLNhbifft6Gk/FzxNNIQiAp85NU6g6nJ8s89adbRzob2W2bNOVjpCOhYiYWiNDJrzI5bYUTfR81EsmV0LTCML3JZbr89Mzkzx5dpJMLETFdulMRUhEDLozUe7b3cHBSzO0JyPs6EgE8c84EVOj6njMlm0MXWNLa4x8xcH2fMqWxzdfGOIDd/WueP2mEYShCeIhnbKtuiXMVWx0TTA0W23kaD91dgrL8/F9GTQ9hIipsbMziSYELw3NkQgb3NaT4cJUmYrt4noSQxecHiveGEHg/X1ZbuvN8K0XhomYOu3JMHt70gxMVzg/WWJzS4zB2Spv2pGjYisv1JaWGKahkYoYXJgs8y/2djFXcbhnWyuPvDTSyM1+/74e9m1p4cAKjCJNIQgB3NXXwq8f2MKuzpSieE1FqNoeEVMFb3VNULFcUlHzFWMEgOX6hA2tkcHfn4vjS8mFyTL7+1rQBDdGEPi9d3Sja4K7t7aojgko63G+9lg8l5iPenJ63exuDSqCM7FQgxF1JTTFPEIChwZmOT5SaPTUutaqnflQdLCrSz1qCkEA/MPPBvjdL7/As+encX1/qfjKmiClbNR7yMC3uRKa5tU4NpJnqmjzp48c5917N7GjI4kmaASCExGDqKk3jK+WuOq143h+cNevRMqlhLCp8b1jozy4dxNTJYuz4+tsavjzgkBV5p0dL/Hpx84EvPmqvrszHSEbM9nVmeKloTmKNZf7dreTiZmcGi3yjps7ycRMvnt0lLChs7cnTbHm8s0Xhnju4gwvD81hu/76/BFCiJ2oYG8d/cAfoyifN6wS+MFbu9jdpXixh2YVDVvZVr00fCk5OVrk5aE8QqhB87GTE0yVLISAmYqN50tOjBQwdY2Zss2TZycp2x6nxorc3pvhrr4Uh1d4PdZUyhRwYw+j4hW/DczIK5XAWSnlxwJK2N8NBPE64DNSyhUrgffv3y+feOZnDTbTo8N5drQnKVsup8eLtMZDVGzVwytiqAmUoWuMF2rUHJ+bN6W4MFmi5qi7fueWLI+8NMJzF6cxNI0Pv2kr29oSbN3cPTAxPt635I9Yi9sdVeH3tLwOQWDf92UliIjnK/aSbvy1fGzXk8OzFTlRqDWYkTeiEriODwBfCZY3NAg8PFvlf/7kPJ6vGIbqdZvBvkuqwKXSkOsfU9fYFJRBDsxUVpxew9oo40PALxIQAc+HlFIKIdYcBCagg963f7/80+8c55lz01Qdj21tcWqOilveu6sdy/XpyUZJRAyGZipEQwb5ik1PSwxDU75L11NEv6YuSEbMgLbJp2x7fPGZS0q466VNCPBO4AUpZb1x74YGgc+MlbitN8PfPzuARCIQJMIGXzs0SNX2yCVCtMRDTJVs2pJhClWnwSmzpTWGlHBuooQQyk331NkpJoo1oiEDgeojulH1Gr/KldcCNrgS+KNv3cb9ezp4eShPMmwgkcpF7ysXfiJsoGsaEkl3Jort+aqVXcggFVF52FVbkYCPFWr05+IUay67N6U4O17ijdtz/M1if958rHKQjKNIvtPz1rWi+PTPAo8BLcF6wZXe4keB/dcW+7wS01wuHrocjg3PLdh3umRddbBcbZF8OfjH56+bRqUILN5XolTrmrBSUcm12hz141pW0fmtaWaW68X8+VDLVZqKLIWmMbp8X1Kx19cTuM5B1ZmOXHXfxWgaQfzTkWH+6kfncJcI/K4WlcDNV38l6kQcV7MzoEleDQl8+odnKNse02Wbt+1sw9A09m3JYuiC4dkqmZiJrl1pc2nMK1kI6arzguP5jQz/C5Nljo/kuXNLVjEiZmMbNo+4rtjWluDm7hRfePoSXz802IiEIxRZVyJsEAsZxMNXktFDhgYSelpiTBUtaq56Iu7f08HzF2d46twUXekIr9+W4+RoofkJuQTw3z5wOxFT52072/npGUUF7fo+mVgosCgtypZHKmqwtyfDdMkiHjYIGzr5qk0mFsL3JZemy6SjJoWqQ1c6yoN7u9jbm8bx5PrnEdf7Mz/z1vf9FfOpltu2eM7huF5jPlHHDZFDVYcQ4hUB3flYaVv9eFCR8UTIWFzAsuwo0TRaY6MhBGxujS1YNz09Pbfs/uvR2xsFIUQR5be4FuRQLbBWgy1SyralNjTLq3FaSrn/Wg4UQhy61mPn43/bV2OteE0QAZpFEJ99lY5toCkGy2ZAszwRrzpedUEIIR4QQpwWQpwL4iMr7XtJCHFUCHFECHEoWNcihPihEOJs8Dd7TT/k1ZxaAzrKpdePqh58Cdizwv6XeCXT6pLVhmv9vNpPxN2odpkXpJQ2qi/ge9Z4jvegyjEJ/r73Wn7Iqy2IVQWD5kGyesrZNaFZZparxRullMNCiHbgh0KIU/M3Srn2QFMdr/YTsaZgkJxHOQs8zDzKWYBFgaY14dUWxEFghxBiaxBS/AAqQPQKCCHiQohkfRkVkD7GlUATLAw0rQ2vptYIRvp3AWdQ2uPfr7BfP0qrvAQcr+/LMoGmtX5em1kGeLVfjabBa4II8JogArwmiACvCSLAa4II8JogArwmiAD/P+QWocjtZTJIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check training images\n",
    "plt.figure()\n",
    "plt.imshow(training_data[0])\n",
    "\n",
    "print(training_data[0].shape)\n",
    "plt.savefig('test3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3340 - accuracy: 0.5005 - val_loss: 0.3104 - val_accuracy: 0.5044\n",
      "Epoch 2/10\n",
      " 901/1875 [=============>................] - ETA: 2s - loss: 0.3052 - accuracy: 0.5065"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b8f7dabd294f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m autoencoder_train = autoencoder.fit(trainX, trainX, epochs=epochs,verbose=1,\n\u001b[0m\u001b[1;32m      4\u001b[0m     validation_data=(trainX, trainX))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train build_autoencoder model on the dataset of good and bad spectra\n",
    "#total training set is 1000 images, 700 \"good\" and 300 of the \"bad\" 1 diff and 2 diff images\n",
    "\n",
    "epochs= 5\n",
    "\n",
    "#split data\n",
    "X_train,X_valid,X_test,X_test = train_test_split(training_data, training_data,\n",
    "                                                             test_size=0.2, random_state=13, \n",
    "                                                             shuffle=True)\n",
    "\n",
    "autoencoder_train = autoencoder.fit(X_train, X_train, epochs=epochs,verbose=1,\n",
    "    validation_data=(ground_train, ground_train))\n",
    "\n",
    "# Model evaluation\n",
    "scores = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "#save weights & model\n",
    "# autoencoder = autoencoder.save_weights('autoencoder_weights.h5')\n",
    "# autoencoder.save(\"autoencoder.h5py\")\n",
    "\n",
    "accuracy = autoencoder_train.history['accuracy']\n",
    "val_accuracy = autoencoder_train.history['val_accuracy']\n",
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax1.plot(epochs, accuracy, 'r--', label='Training accuracy')\n",
    "ax1.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "ax1.set_title('Training and validation accuracy')\n",
    "ax1.legend()\n",
    "ax2.plot(epochs, loss, 'r--', label='Training loss')\n",
    "ax2.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax2.set_title('Training and validation loss')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visually inspect reconstructions to test accuracy\n",
    "pred = autoencoder.predict(testX)\n",
    "plt.figure(figsize=(20, 4))\n",
    "print(\"Test Images\")\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(testX[i, ..., 0], cmap='gray')\n",
    "    curr_lbl = testX[i]\n",
    "    #plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "plt.show()    \n",
    "plt.figure(figsize=(20, 4))\n",
    "print(\"Reconstruction of Test Images\")\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(pred[i, ..., 0], cmap='gray')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
